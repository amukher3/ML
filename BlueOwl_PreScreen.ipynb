{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Name: Mukherjee\n",
    "Date: 1/31/2019\n",
    "Approach: A 2-layered perceptron or a 2-layered neural net. \n",
    "Estimated AUC: I expect the AUC on the test-set to be greater than 0.85. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train=pd.read_csv(\"C:/Users/abhi0/Downloads/train.csv\")\n",
    "df_test=pd.read_csv(\"C:/Users/abhi0/Downloads/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreProcess(df):\n",
    "    \n",
    "    #Getting dummies for 'device_type' feature\n",
    "    df_dummies=pd.get_dummies(df['device_type'],prefix='category')\n",
    "    df=pd.concat([df,df_dummies],axis=1)\n",
    "\n",
    "    df=df.drop(['device_type'],axis=1)\n",
    "\n",
    "    #filling the missing valeus in gender vector\n",
    "    df=df.fillna('M')\n",
    "\n",
    "    #label encoding gender\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    df['gender'] = labelencoder_X.fit_transform(df['gender'])\n",
    "\n",
    "    #Normalizing the datasets\n",
    "    #Same factor should be there for test and train\n",
    "    df[\"income\"] = df[\"income\"] / df['income'].max()\n",
    "    df[\"age\"] = df[\"age\"] / df[\"age\"].max()\n",
    "    df[\"cost_of_ad\"] = df[\"cost_of_ad\"] / df[\"cost_of_ad\"].max()\n",
    "    \n",
    "    \n",
    "    return df \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For training and testing the classifier\n",
    "#df_processed_train -- pre-processed training data-set\n",
    "#df_processed_test --- pre-processed test data-set\n",
    "\n",
    "def buildingClassifier(df_processed_train,df_processed_test):\n",
    "    \n",
    "    ############### Separating the traning set into train and dev sets ##################\n",
    "    \n",
    "    #For the training data frame separating into dependent and independednt variables. \n",
    "    #Further,separating the dependednt variable into into training and dev.set\n",
    "    #25-75 ratio adapted. \n",
    "    \n",
    "    #Separating the independent variable:\n",
    "    Y=df_processed_train['outcome']\n",
    "\n",
    "    X=df_processed_train.drop(['outcome'],axis=1)\n",
    "    \n",
    "    #### Splitting the datasets\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X, Y, test_size = 0.25, random_state = 0) \n",
    "    \n",
    "    ################################# training the classifier ##################################\n",
    "    \n",
    "    #Parameters arrived after\n",
    "    #grid search.\n",
    "    roc_auc_test=[]\n",
    "    Activation='sigmoid'\n",
    "    Optimizer='rmsprop'\n",
    "    BatchSize=50\n",
    "    ActivityRegularizer=0.001\n",
    "    \n",
    "    # Initialising the ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 13, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13,\n",
    "                         activity_regularizer=l2(ActivityRegularizer)))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 7,kernel_initializer = 'uniform', activation = 'relu',\n",
    "                                    activity_regularizer=l2(ActivityRegularizer)))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 1,kernel_initializer = 'uniform', activation ='sigmoid',\n",
    "                                    activity_regularizer=l2(ActivityRegularizer)))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = Optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "    classifier.fit(X_train, y_train, batch_size = BatchSize, epochs = 50)\n",
    "\n",
    "    ##################### Making the predictions and evaluating the model ######################\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred_dev = classifier.predict(X_dev)\n",
    "\n",
    "    #AUC on the dev-set\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, _ = roc_curve(y_dev, y_pred_dev)\n",
    "    auc_devSet=auc(fpr, tpr)\n",
    "    \n",
    "    \n",
    "    ##################################### Tesing the classifier #####3#############################\n",
    "    \n",
    "    # Predicting the Test set results\n",
    "    X_test=df_processed_test\n",
    "    \n",
    "    #y_pred_test is the predicted outcome\n",
    "    #from the pre-processed test set. \n",
    "    y_pred_test = classifier.predict(X_test)\n",
    "    y_pred_test[y_pred_test>0.5]=1                \n",
    "    y_pred_test[y_pred_test<=0.5]=0\n",
    "    \n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.6443 - accuracy: 0.9057\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4913 - accuracy: 0.9057\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.4018 - accuracy: 0.9057\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3564 - accuracy: 0.9057\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3313 - accuracy: 0.9057\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3158 - accuracy: 0.9057\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3040 - accuracy: 0.9057\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2959 - accuracy: 0.9057\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.2888 - accuracy: 0.9057\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2825 - accuracy: 0.9057\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2787 - accuracy: 0.9057\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2762 - accuracy: 0.9057\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2740 - accuracy: 0.9057\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.2725 - accuracy: 0.9057\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.2704 - accuracy: 0.9057\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.2692 - accuracy: 0.9057\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.2679 - accuracy: 0.9057\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.2666 - accuracy: 0.9057\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.2668 - accuracy: 0.9057\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.2657 - accuracy: 0.9057\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.2639 - accuracy: 0.9057\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.2642 - accuracy: 0.9057\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.2617 - accuracy: 0.9057\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.2622 - accuracy: 0.9057\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.2586 - accuracy: 0.9057\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2604 - accuracy: 0.9057\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2592 - accuracy: 0.9057\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2578 - accuracy: 0.9057\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2569 - accuracy: 0.9057\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.2565 - accuracy: 0.9057\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2551 - accuracy: 0.9057\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2547 - accuracy: 0.9057\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2553 - accuracy: 0.9057\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2538 - accuracy: 0.9057\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2537 - accuracy: 0.9057\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.2524 - accuracy: 0.9057\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.2530 - accuracy: 0.9057\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2532 - accuracy: 0.9057\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2519 - accuracy: 0.9057\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2508 - accuracy: 0.9057\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2503 - accuracy: 0.9057\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2506 - accuracy: 0.9057\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.2498 - accuracy: 0.9057\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.2504 - accuracy: 0.9057\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.2486 - accuracy: 0.9057\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2499 - accuracy: 0.9057\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2487 - accuracy: 0.9057\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2488 - accuracy: 0.9057\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.2485 - accuracy: 0.9057\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.2490 - accuracy: 0.9057\n"
     ]
    }
   ],
   "source": [
    "#Predicted Outcomes are the predicted results on the given test set i.e 'y_pred_test'\n",
    "PredictedOutcomes=buildingClassifier(DataPreProcess(df_train),DataPreProcess(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Printing the first five predictions \n",
    "\n",
    "print(PredictedOutcomes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
